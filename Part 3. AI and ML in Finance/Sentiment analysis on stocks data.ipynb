{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sentiment analysis on stock data\n",
    "\n",
    "Motivation: Social media, media feeds and news articles produce enormous data quantities relevant to stocks daily, which can be leveraged to predict the general public's feeling towards particular companies and their stock value. This data is in the form of text, which must be converted into numbers to be useful in large scale. To convert the available data, natural language processing (NLP) methods are used. In this notebook, a sentiment analysis ML model will be developed, analyzing tweets and making recommendations about the course of action on specific stocks.\n",
    "\n",
    "The data is part of [this Udemy course](https://www.udemy.com/course/ml-and-python-in-finance-real-cases-and-practical-solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 0: Import the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "# Start by importing the modules needed in the notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import one_hot,Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Embedding, Input, LSTM, Conv1D, MaxPool1D, Bidirectional, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                Text  Sentiment\n0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n2  user I'd be afraid to short AMZN - they are lo...          1\n3                                  MNTA Over 12.00            1\n4                                   OI  Over 21.37            1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>user I'd be afraid to short AMZN - they are lo...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MNTA Over 12.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>OI  Over 21.37</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the stock news data\n",
    "stocks_df = pd.read_csv(\"stock_sentiment.csv\")\n",
    "stocks_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Show dataframe information\n",
    "stocks_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5791 entries, 0 to 5790\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Text       5791 non-null   object\n",
      " 1   Sentiment  5791 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "Text         0\nSentiment    0\ndtype: int64"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "stocks_df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# How many unique entries are in the \"Sentiment\" column?\n",
    "print(\"In this setting there are %s possible sentiments.\" %len(stocks_df['Sentiment'].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this setting there are 2 possible sentiments.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 1: Data cleaning\n",
    "\n",
    "Text data cleaning is a bit more complex than numerical data cleaning. Besides potential null values, for which we already checked, punctuation and \"stop words\" (e.g. \"and\", \"or\", etc) must be removed from the data, since they do not provide useful information and bloat the dataset.\n",
    "\n",
    "### Part 1a: Removing punctuations\n",
    "\n",
    "Before cleaning the data, we experiment with the relevant python capabilities."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The punctuation characters to be removed are: \n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print('The punctuation characters to be removed are: \\n' + string.punctuation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence\n",
      " This is an, admittedly small, example. \n",
      " looks like this after removing punctuation: \n",
      " This is an admittedly small example \n"
     ]
    }
   ],
   "source": [
    "example = 'This is an, admittedly small, example.'\n",
    "example_clean = ''.join([c for c in example if c not in string.punctuation])\n",
    "\n",
    "print('The sentence\\n %s \\n looks like this after removing punctuation: \\n %s ' %(example, example_clean))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "# Define a punctuation removing function.\n",
    "# Input: a string\n",
    "# Output: the string with punctuation characters removed\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return ''.join([c for c in text if c not in string.punctuation])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                Text  Sentiment  \\\n0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1   \n1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1   \n2  user I'd be afraid to short AMZN - they are lo...          1   \n3                                  MNTA Over 12.00            1   \n4                                   OI  Over 21.37            1   \n\n                                Text w/o punctuation  \n0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...  \n1  user AAP MOVIE 55 return for the FEAGEED indic...  \n2  user Id be afraid to short AMZN  they are look...  \n3                                   MNTA Over 1200    \n4                                    OI  Over 2137    ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Sentiment</th>\n      <th>Text w/o punctuation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n      <td>1</td>\n      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n      <td>1</td>\n      <td>user AAP MOVIE 55 return for the FEAGEED indic...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>user I'd be afraid to short AMZN - they are lo...</td>\n      <td>1</td>\n      <td>user Id be afraid to short AMZN  they are look...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MNTA Over 12.00</td>\n      <td>1</td>\n      <td>MNTA Over 1200</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>OI  Over 21.37</td>\n      <td>1</td>\n      <td>OI  Over 2137</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the clean function on the stock data\n",
    "\n",
    "stocks_df['Text w/o punctuation'] = stocks_df['Text'].apply(remove_punctuation)\n",
    "stocks_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1b: Remove stopwords\n",
    "\n",
    "To work with text data, the 'string' module is insufficient, therefore the ntlk module is used. In addition to stopwords, all words of one or two letters and the words 'from', 'subject', 're', 'edu', 'use', 'will', 'aap', 'co', 'day', 'user', 'stock', 'today', 'week', 'year', 'http', 'https' will be removed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some stopwords are: \n",
      "i me my myself we our ours ourselves you you're\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/anas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "print('Some stopwords are: \\n'+ ' '.join(stop_words[:10]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "# Extend the stop_words list\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'will', 'aap', 'co', 'day', 'user', 'stock', 'today', 'week', 'year', 'http', 'https'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "# Define the stopword removing function\n",
    "def remove_stopwords(text):\n",
    "    res = []\n",
    "    for token in gensim.utils.tokenize(text):\n",
    "        if len(token)>2 and token not in stop_words:\n",
    "            res.append(token)\n",
    "    #Join the individual words back into a single string\n",
    "    res = ' '.join(res)\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                Text  \\\n0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...   \n1  user: AAP MOVIE. 55% return for the FEA/GEED i...   \n2  user I'd be afraid to short AMZN - they are lo...   \n3                                  MNTA Over 12.00     \n4                                   OI  Over 21.37     \n\n                                Text w/o punctuation  \\\n0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...   \n1  user AAP MOVIE 55 return for the FEAGEED indic...   \n2  user Id be afraid to short AMZN  they are look...   \n3                                   MNTA Over 1200     \n4                                    OI  Over 2137     \n\n                                  Text w/o stopwords  \\\n0  Kickers watchlist XIDE TIT SOQ PNK CPW BPZ tra...   \n1  AAP MOVIE return FEA GEED indicator trades AWE...   \n2  afraid short AMZN looking like near monopoly e...   \n3                                          MNTA Over   \n4                                               Over   \n\n                  Text w/o stopwords and punctuation  \n0  Kickers watchlist XIDE TIT SOQ PNK CPW BPZ tra...  \n1  AAP MOVIE return FEA GEED indicator trades AWE...  \n2  afraid short AMZN looking like near monopoly e...  \n3                                          MNTA Over  \n4                                               Over  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Text w/o punctuation</th>\n      <th>Text w/o stopwords</th>\n      <th>Text w/o stopwords and punctuation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n      <td>Kickers watchlist XIDE TIT SOQ PNK CPW BPZ tra...</td>\n      <td>Kickers watchlist XIDE TIT SOQ PNK CPW BPZ tra...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n      <td>user AAP MOVIE 55 return for the FEAGEED indic...</td>\n      <td>AAP MOVIE return FEA GEED indicator trades AWE...</td>\n      <td>AAP MOVIE return FEA GEED indicator trades AWE...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>user I'd be afraid to short AMZN - they are lo...</td>\n      <td>user Id be afraid to short AMZN  they are look...</td>\n      <td>afraid short AMZN looking like near monopoly e...</td>\n      <td>afraid short AMZN looking like near monopoly e...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MNTA Over 12.00</td>\n      <td>MNTA Over 1200</td>\n      <td>MNTA Over</td>\n      <td>MNTA Over</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>OI  Over 21.37</td>\n      <td>OI  Over 2137</td>\n      <td>Over</td>\n      <td>Over</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the text\n",
    "stocks_df['Text w/o stopwords'] = stocks_df['Text'].apply(remove_stopwords)\n",
    "stocks_df['Text w/o stopwords and punctuation'] = stocks_df['Text w/o stopwords'].apply(remove_punctuation)\n",
    "stocks_df.drop(columns=['Sentiment']).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 2: Create a wordcloud from the text data\n",
    "\n",
    "The wordcloud does not offer any significant insights, but it can be used to illustrate the most frequently appearing words."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize all text data\n",
    "word_cloud = WordCloud(width=500, height=300)\n",
    "word_cloud = WordCloud.generate(word_cloud, ' '.join(stocks_df['Text'].values))\n",
    "print('Wordcloud of the original text data:')\n",
    "word_cloud.to_image()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize the text without punctuation and stopwords\n",
    "word_cloud = WordCloud(width=500, height=300)\n",
    "word_cloud = WordCloud.generate(word_cloud, ' '.join(stocks_df['Text w/o stopwords and punctuation'].values))\n",
    "print('Wordcloud of the clean text data:')\n",
    "word_cloud.to_image()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Visualize the texts with positive sentiment\n",
    "word_cloud_pos = WordCloud(width=500, height=300)\n",
    "word_cloud_pos = WordCloud.generate(word_cloud, ' '.join(stocks_df[stocks_df['Sentiment']==1]['Text w/o stopwords and punctuation'].values))\n",
    "print('Wordcloud of text data with positive sentiment:')\n",
    "word_cloud_pos.to_image()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Visualize the texts with negative sentiments\n",
    "word_cloud_neg = WordCloud(width=500, height=300)\n",
    "word_cloud_neg = WordCloud.generate(word_cloud, ' '.join(stocks_df[stocks_df['Sentiment']==0]['Text w/o stopwords and punctuation'].values))\n",
    "print('Wordcloud of text data with negative sentiment:')\n",
    "word_cloud_neg.to_image()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Two stock names stand out in both cases: [AAP](https://www.marketwatch.com/investing/stock/aap) (Advance Auto Parts) and [GOOG](https://www.marketwatch.com/investing/stock/goog) (Alphabet, aka Google), whereas [AMZN](https://www.marketwatch.com/investing/stock/goog) only appears in the negative sentiment data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 3: Visualize the clean texts\n",
    "\n",
    "The final step of the exploratory data analysis is a statistical analysis of the available data with the corresponding graphs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Break up the strings into words using tokenize\n",
    "nltk.download('punkt')\n",
    "stocks_df['Text tokenized'] = stocks_df['Text w/o stopwords and punctuation'].apply(word_tokenize)\n",
    "stocks_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Examine the length of the tweets\n",
    "stocks_df['Tweet length'] = stocks_df['Text tokenized'].apply(len)\n",
    "stocks_df['Tweet length'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the tweet length against the absolute frequency\n",
    "stocks_df['Tweet length'].hist(bins=50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the positive sentiment tweet length\n",
    "print('Postive sentiment tweet length:')\n",
    "stocks_df[stocks_df['Sentiment']==1]['Tweet length'].hist(bins=50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the negative sentiment tweet length\n",
    "print('Negative sentiment tweet length:')\n",
    "stocks_df[stocks_df['Sentiment']==0]['Tweet length'].hist(bins=50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Observe that some tweets must be removed, since they only contained removed words."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stocks_df = stocks_df[stocks_df['Text tokenized'].apply(len)>1]\n",
    "stocks_df['Tweet length'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 4: Preprocessing\n",
    "\n",
    "At this stage the data must be prepared for the machine learning model.\n",
    "The tweets need to be padded to the same length, and the words must be tokenized."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the total length of the text\n",
    "total_length = stocks_df['Text tokenized'].apply(len).sum()\n",
    "print('The cleaned dataset has %s words' %total_length)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the unique words in the dataset\n",
    "unique_words = stocks_df['Text tokenized'].explode().unique()\n",
    "print('The dataset has %s unique words' %len(unique_words))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset isnow split into train and test set. Preprocessing will use only the train set in order to simulate the effects that unknown words will have on the model. In a real world application, there is no guarantee that the train set contains all words that occur in tweets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split into X and y (input and output)\n",
    "X = stocks_df['Text w/o stopwords and punctuation']\n",
    "y = stocks_df['Sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "X_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a tokenizer and fit it on the train set\n",
    "tokenizer = Tokenizer(num_words = total_length)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "# Apply the tokenizer on the train and test tweets\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "# Show the first 5 train sequences\n",
    "train_sequences[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pad the sequences to the max length\n",
    "train_padded = pad_sequences(train_sequences, maxlen=20)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "At this point the input data is ready. The output needs to be converted to categorical before proceeding."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert the sentiment to categorical data\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}